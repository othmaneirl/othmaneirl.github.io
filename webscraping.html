<!DOCTYPE html>
<html lang="fr">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Rapport de Stage - Web Scraping et Analyse de Données</title>
  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <script src="https://kit.fontawesome.com/7b013b52e3.js" crossorigin="anonymous"></script>
</head>

<body>
  <header>
    <h1>Web Scraping et Analyse de Données</h1>
    <h2 id="titre">Rapport de Stage</h2>
    <div class="contact-info">
      <p><i class="fas fa-user"></i> IRHBOULA Othmane</p>
      <p><i class="fas fa-calendar"></i> 2023</p>
      <p><i class="fab fa-github"></i> <a href="https://github.com/othmaneirl/WebScrap" target="_blank">GitHub Repository</a></p>
    </div>
  </header>

  <main>
    <section>
      <button class="section-header">
        <i class="fas fa-info-circle"></i> Description du projet
      </button>
      <div class="content">
        <p>Stage de découverte du domaine numérique axé sur le web scraping et l'analyse de données, impliquant l'extraction d'informations de divers sites web et leur traitement pour enrichir les bases de données existantes.</p>
      </div>
    </section>

    <section>
      <button class="section-header">
        <i class="fas fa-tasks"></i> Objectifs et Méthodologie
      </button>
      <div class="content">
        <ul>
          <li>Développer des scripts d'extraction de données de sites web spécifiques</li>
          <li>Utiliser des technologies comme BeautifulSoup et Selenium pour le web scraping</li>
          <li>Croiser les données scrapées avec les bases existantes</li>
          <li>Découvrir et utiliser le langage R pour l'analyse et la visualisation de données</li>
        </ul>
      </div>
    </section>

    <section>
      <button class="section-header">
        <i class="fas fa-code"></i> Technologies et Outils utilisés
      </button>
      <div class="content">
        <ul>
          <li>Python avec les bibliothèques BeautifulSoup et Selenium</li>
          <li>MongoDB pour le croisement de données</li>
          <li>Langage R pour l'analyse et la visualisation</li>
          <li>Utilisation de proxys pour contourner les restrictions d'accès</li>
        </ul>
      </div>
    </section>

    <section>
      <button class="section-header">
        <i class="fas fa-globe"></i> Sites Scrapés et Méthodes
      </button>
      <div class="content">
        <p>Différentes approches ont été utilisées selon les sites :</p>
        <ul>
          <li>Charika.ma : Extraction des URL avec BeautifulSoup, puis des informations avec Selenium</li>
          <li>Marché Public : Utilisation de Selenium pour l'extraction et le téléchargement de pièces jointes</li>
          <li>Airbnb : Combinaison de BeautifulSoup et Selenium pour l'extraction des données</li>
          <li>Yakee : Utilisation de BeautifulSoup et Selenium pour l'extraction des informations</li>
        </ul>
        <!-- <img src="sites_scrapes.png" alt="Sites scrapés et méthodes utilisées" style="max-width: 100%; height: auto;"> -->
      </div>
    </section>

    <section>
      <button class="section-header">
        <i class="fas fa-cogs"></i> Traitement des Données
      </button>
      <div class="content">
        <ul>
          <li>Nettoyage des datasets extraits sous forme de CSV</li>
          <li>Prétraitement des pièces jointes pour l'IA de reconnaissance d'écriture</li>
          <li>Développement d'un algorithme de comparaison de chaînes pour le rapprochement des données</li>
        </ul>
        <!-- <img src="traitement_donnees.png" alt="Processus de traitement des données" style="max-width: 100%; height: auto;"> -->
      </div>
    </section>

    <section>
      <button class="section-header">
        <i class="fas fa-exclamation-triangle"></i> Défis et Solutions
      </button>
      <div class="content">
        <p>Principaux défis rencontrés et solutions apportées :</p>
        <ul>
          <li>Optimisation du temps d'exécution des scripts de scraping</li>
          <li>Utilisation de proxys pour contourner les restrictions d'accès</li>
          <li>Développement d'un algorithme de comparaison pour le rapprochement des données de différentes sources</li>
        </ul>
      </div>
    </section>

    <section>
      <button class="section-header">
        <i class="fas fa-lightbulb"></i> Résultats et Perspectives
      </button>
      <div class="content">
        <p>Le stage a permis d'enrichir les bases de données existantes avec de nouvelles informations sur les entreprises, notamment :</p>
        <ul>
          <li>Coordonnées lombardes</li>
          <li>Adresses exactes</li>
          <li>Activités des entreprises</li>
        </ul>
        <p>Ces données pourront être utilisées pour améliorer les analyses et les services de la DGI.</p>
      </div>
    </section>
  </main>
  <script src="script.js"></script>
</body>

</html>